{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fce643b4",
   "metadata": {},
   "source": [
    "# Laboratory 1: Property Graphs\n",
    "### Luis Alfredo Leon Villapún\n",
    "### Liliia Aliakberova\n",
    "\n",
    "# Part A.2 Instantiating / Loading\n",
    "* * *\n",
    "In this section we are asked to load the data into our desired graph. To do this, we are going to use mainly the Semantic Scholar dataset. To test, it is recommended to use the sample data comprising 100 papers.  \n",
    "Please note that:  \n",
    "- this datasets are in json format, so we will have to use the <i>apoc</i> library in our Neo4j installation.\n",
    "- this datasets contain modified information to suit this tasks requirements, so even though a part of this dataset is real, some relationships will be fake.\n",
    "\n",
    "## Creating the connector\n",
    "Let's first create the connector to handle the messages with Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f541b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "# !pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38adcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple connector script. Creates a connection to a Neo4j server.\n",
    "References:\n",
    "   - https://neo4j.com/developer/python/\n",
    "   - https://towardsdatascience.com/create-a-graph-database-in-neo4j-using-python-4172d40f89c4\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "import logging\n",
    "\n",
    "\n",
    "class Neo4jConnector:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        logging.basicConfig(filename=\"connector.log\")\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def query(self, query):\n",
    "        session = None\n",
    "        response = None\n",
    "        try:\n",
    "            session = self.driver.session()\n",
    "            response = list(session.run(query))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Query Failed: {e}\")\n",
    "        finally:\n",
    "            if session is not None:\n",
    "                session.close()\n",
    "            return response\n",
    "        \n",
    "    def drop(self):\n",
    "        self.query(query=\"MATCH (n) -[e] -> () DELETE n, e\")\n",
    "        self.query(query=\"MATCH (n) DELETE n\")\n",
    "        logging.info(\"Deleted database. Success.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e44064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input your password to connect········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "uri = \"neo4j://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = getpass(\"Input your password to connect\")\n",
    "conn = Neo4jConnector(uri, user, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6135b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to drop the database (you will have to rerun the loading cells)\n",
    "conn.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d76ce",
   "metadata": {},
   "source": [
    "## Authors Json File\n",
    "First, we will load the authors json file to extract data about the authors in this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee4393a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_authors(conn):\n",
    "    query = \"\"\"\n",
    "        CALL apoc.load.json('file:///samples/authors/authors-sample.jsonl')\n",
    "        YIELD value\n",
    "        MERGE (a:Author {name: value.name})\n",
    "        SET a.author_id = value.authorid, \n",
    "            a.citationcount = value.citationcount, \n",
    "            a.hindex = value.hindex, \n",
    "            a.papercount = value.papercount\n",
    "    \"\"\"\n",
    "    session = conn.driver.session()\n",
    "    response = list(session.run(query))\n",
    "    session.close()\n",
    "    print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41ed06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "load_authors(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d5a7bf",
   "metadata": {},
   "source": [
    "## Publication Venues Json File\n",
    "This file contains extra data on conferences and journals. We will use it to create Event nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56896bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_publication_venues(conn):\n",
    "    query = \"\"\"\n",
    "    CALL apoc.load.json('file:///samples/publication-venues/publication-venues-sample.jsonl')\n",
    "    YIELD value\n",
    "    WITH *\n",
    "    WHERE value.type = 'conference'\n",
    "    MERGE (e: Event {event_name: value.name})\n",
    "    SET e.event_id = value.id,\n",
    "        e.url = value.url,\n",
    "        e.type= 'conference',\n",
    "        e.edition = apoc.coll.randomItem(['I', 'II', 'III', 'IV', 'V'])\n",
    "    WITH value\n",
    "    WHERE value.type= 'journal'\n",
    "    MERGE (j: Document {name: value.name})\n",
    "    SET j.type = 'journal',\n",
    "        j.document_id = apoc.create.uuid()\n",
    "    \"\"\"\n",
    "    session = conn.driver.session()\n",
    "    response = list(session.run(query))\n",
    "    session.close()\n",
    "    print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dce2021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "load_publication_venues(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb446abd",
   "metadata": {},
   "source": [
    "## Papers Json File\n",
    "This file contains data about multiple nodes and edges of our interest, here, we will create Article nodes related to the papers, extract their authors, create their edge 'WRITEN_BY' and then do the same with the journals related to the papers. We are also adding some random data to create the 'REVIEWED_BY', 'PRESENTED_AT' and 'CITED_BY' edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f816901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, json\n",
    "\n",
    "articles_path = \"/Users/alfredo.leon/Desktop/SDMLab1/neo4jcontainerdata/samples/papers/\"\n",
    "\n",
    "def load_articles(conn, path=articles_path, regenerate=False):\n",
    "    if regenerate:\n",
    "        with open(f\"{path}papers-sample.jsonl\") as papers:\n",
    "            with open(f\"{path}papers-sample-modified.jsonl\", \"w\") as papers_modified:\n",
    "                for paper in papers:\n",
    "                        citations = []\n",
    "                        reviews = []\n",
    "                        editions = []\n",
    "                        paper = json.loads(paper.strip(\"\\n\"))\n",
    "\n",
    "                        num_citations = random.randint(0, 5)\n",
    "                        if num_citations > 0 and paper['corpusid'] not in [196432386, 211536971, 188341797, 220921189, 227616401]:\n",
    "                            cited_ids = random.sample([196432386, 211536971, 188341797, 220921189, 227616401], num_citations)\n",
    "                            for cite_id in cited_ids:\n",
    "                                citations.append({\"article_id\": cite_id})\n",
    "                        paper['citations'] = citations\n",
    "\n",
    "                        num_reviews = random.randint(0, 3)\n",
    "                        if num_reviews > 0:\n",
    "                            author_ids = [author['authorId'] for author in paper['authors']]\n",
    "                            reviewer_ids = random.sample([\"143973205\",\"152609652\",\"149287618\",\"118712934\",\"134641171\",\n",
    "                                                          \"121778794\",\"145466716\",\"116765497\",\"103479334\",\"146897159\",\n",
    "                                                          \"122972940\",\"146578621\"], num_reviews)\n",
    "                            if len(set(author_ids).intersection(set(reviewer_ids))) == 0:\n",
    "                                for reviewer_id in reviewer_ids:\n",
    "                                    reviews.append({\"reviewer_id\": reviewer_id})\n",
    "                        paper['reviewers'] = reviews\n",
    "\n",
    "                        num_topics = random.randint(1, 11)\n",
    "                        topics = []\n",
    "                        if num_topics > 0:\n",
    "                            topics = random.sample([\"data management\", \"indexing\", \"data modeling\", \"big data\", \"data processing\", \n",
    "                                                    \"data storage\", \"data querying\", \"biology\", \"gene therapy\", \"proteins\", \"crispr\"], num_topics)\n",
    "                        paper['topics'] = {\"topic\": topic for topic in topics}\n",
    "\n",
    "                        paper['presented_at'] = {\n",
    "                            'conference_id': random.choice([\"30a20a37-c3ce-47f2-8a81-e59c4f39502c\", \n",
    "                                                            \"b41a8ed2-0658-4761-b625-32bf9c5fbf69\", \n",
    "                                                            \"32700c08-d377-4a78-9532-370593d65166\"]),\n",
    "                            'edition': random.choice(['I', 'II', 'III', 'IV', 'V']),\n",
    "                        }\n",
    "\n",
    "                        papers_modified.write(json.dumps(paper) + \"\\n\")\n",
    "                    \n",
    "    query = \"\"\"\n",
    "        CALL apoc.load.json('file:///samples/papers/papers-sample-modified.jsonl')\n",
    "        YIELD value\n",
    "        MERGE (article: Article {title: value.title})\n",
    "        SET article.article_id = value.corpusid,\n",
    "            article.content = value.url\n",
    "        WITH article, value\n",
    "        UNWIND value.authors AS author\n",
    "        MERGE (auth: Author {name: author.name})\n",
    "        SET auth.author_id = author.authorId\n",
    "        MERGE (auth)<-[:WRITEN_BY]-(article)\n",
    "        WITH article, value\n",
    "        UNWIND value.journal AS journal\n",
    "        MERGE (j: Document {name: journal.name})\n",
    "        SET j.type = 'journal',\n",
    "            j.volume = journal.volume,\n",
    "            j.document_id = apoc.create.uuid()\n",
    "        MERGE (article)-[:PUBLISHED_AT]->(j)\n",
    "        WITH article, value\n",
    "        UNWIND value.citations as citation\n",
    "        MATCH (cited: Article {article_id: citation.article_id})\n",
    "        MERGE (cited)-[:CITED_BY]->(article)\n",
    "        WITH article, value\n",
    "        UNWIND value.reviewers AS review\n",
    "        MATCH (reviewer: Author {author_id: review.reviewer_id})\n",
    "        MERGE (article)-[:REVIEWED_BY]->(reviewer)\n",
    "        WITH article, value\n",
    "        UNWIND value.presented_at as presented_at\n",
    "        MATCH (event: Event {event_id: presented_at.conference_id})\n",
    "        MERGE (article)-[:PRESENTED_AT {edition: presented_at.edition}]->(event)\n",
    "        MERGE (d: Document {type: 'proceeding', name: event.event_name, document_id: apoc.create.uuid()})-[:EDITED_BY {edition: presented_at.edition}]->(event)\n",
    "        WITH article, value\n",
    "        UNWIND value.topics as topic\n",
    "        MERGE (t: Topic {keyword: topic.topic})\n",
    "        MERGE (article)-[:RELATES_TO]->(t)\n",
    "    \"\"\"\n",
    "    session = conn.driver.session()\n",
    "    response = list(session.run(query))\n",
    "    session.close()\n",
    "    print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "177b80c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "load_articles(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e096b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
